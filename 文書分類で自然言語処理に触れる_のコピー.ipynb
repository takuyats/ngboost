{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "文書分類で自然言語処理に触れる のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takuyats/ngboost/blob/master/%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%81%A7%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%81%AB%E8%A7%A6%E3%82%8C%E3%82%8B_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a9CUjgUXgB6",
        "colab_type": "text"
      },
      "source": [
        "# 文書分類で自然言語処理に触れる\n",
        "<提供>\n",
        "- 高橋寛治 [@kanji250tr](https://twitter.com/kanji250tr)\n",
        "- [スライド資料リンク](https://docs.google.com/presentation/d/e/2PACX-1vQHjfOTrH-xu49F6iINswP99AedOSgkYLlc4smMkkCi-GJ1WrA3CKAPr8epiRR8Cy4t021tP_6MWf7f/pub?start=false&loop=false&delayms=3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN2ubfIUYnhi",
        "colab_type": "text"
      },
      "source": [
        "## 概要\n",
        "本資料は、Pythonを用いて文書分類を行うことで、自然言語処理に触れることを目的としています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OhMl2DTX_xE",
        "colab_type": "text"
      },
      "source": [
        "## 環境構築\n",
        "- 形態素解析器MeCabのインストール\n",
        "- livedoorニュースコーパスの入手"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZWMRINHYwme",
        "colab_type": "text"
      },
      "source": [
        "### 形態素解析器のインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td5F61-PjZaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get -y install mecab libmecab-dev mecab-ipadic-utf8 > /dev/null\n",
        "!pip install mecab-python3 > /dev/null\n",
        "!pip install ngboost > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtfezSifYzt8",
        "colab_type": "text"
      },
      "source": [
        "### livedoorニュースコーパスの取得と整理\n",
        "wgetコマンドによりダウンロードしたものを展開する。\n",
        "\n",
        "README.txtを表示する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPRcRq8dw9Es",
        "colab_type": "code",
        "outputId": "30b8c90d-875c-4fb3-c71e-ccb3a058b17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-10 00:03:00--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz.2’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  1.89MB/s    in 4.5s    \n",
            "\n",
            "2020-04-10 00:03:06 (1.89 MB/s) - ‘ldcc-20140209.tar.gz.2’ saved [8855190/8855190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeHbHlL9xCbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar zxf ldcc-20140209.tar.gz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vEStcjmxLkn",
        "colab_type": "code",
        "outputId": "38bd0a00-f92b-43a2-ef2b-94777bdebcd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat text/README.txt"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "livedoor ニュースコーパス\n",
            "\n",
            "\n",
            "概要\n",
            "-----------------\n",
            "本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズ\n",
            "ライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。\n",
            "\n",
            "- トピックニュース\n",
            "  http://news.livedoor.com/category/vender/news/\n",
            "- Sports Watch\n",
            "  http://news.livedoor.com/category/vender/208/\n",
            "- ITライフハック\n",
            "  http://news.livedoor.com/category/vender/223/\n",
            "- 家電チャンネル\n",
            "  http://news.livedoor.com/category/vender/kadench/\n",
            "- MOVIE ENTER\n",
            "  http://news.livedoor.com/category/vender/movie_enter/\n",
            "- 独女通信\n",
            "  http://news.livedoor.com/category/vender/90/\n",
            "- エスマックス\n",
            "  http://news.livedoor.com/category/vender/smax/\n",
            "- livedoor HOMME\n",
            "  http://news.livedoor.com/category/vender/homme/\n",
            "- Peachy\n",
            "  http://news.livedoor.com/category/vender/ldgirls/\n",
            "\n",
            "収集時期：2012年9月上旬\n",
            "\n",
            "\n",
            "ライセンス\n",
            "-----------------\n",
            "各記事ファイルにはクリエイティブ・コモンズライセンス「表示 - 改変禁止」\n",
            "（http://creativecommons.org/licenses/by-nd/2.1/jp/）が適用されます。\n",
            "クレジット表示についてはニュースカテゴリにより異なるため、サブディレクトリにある\n",
            "それぞれの LICENSE.txt をご覧ください。\n",
            "\n",
            "livedoor はNHN Japan株式会社の登録商標です。\n",
            "\n",
            "\n",
            "記事ファイルのフォーマット\n",
            "-----------------\n",
            "記事ファイルは以下のフォーマットにしたがって作成されています：\n",
            "\n",
            "１行目：記事のURL\n",
            "２行目：記事の日付\n",
            "３行目：記事のタイトル\n",
            "４行目以降：記事の本文\n",
            "\n",
            "\n",
            "管理者／連絡先\n",
            "-----------------\n",
            "本コーパスに関するお問い合わせは、記事を収集した下記会社宛にお願いいたします：\n",
            "\n",
            "株式会社ロンウイット\n",
            "http://www.rondhuit.com/\n",
            "メール：sales@rondhuit.com\n",
            "\n",
            "\n",
            "謝辞\n",
            "-----------------\n",
            "「livedoor ニュース」の一部をクリエイティブ・コモンズライセンスのもと公開してくださいました\n",
            "NHN Japan株式会社様に感謝いたします。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ksPgPpZPKP",
        "colab_type": "text"
      },
      "source": [
        "カテゴリとテキストが、どのようなディレクトリやファイルになっているかを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zQsRHuQZY24",
        "colab_type": "code",
        "outputId": "64e19acc-b1b8-419f-bfba-0551527f45b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!ls ./text"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHANGES.txt\tkaden-channel\tpeachy\t    sports-watch\n",
            "dokujo-tsushin\tlivedoor-homme\tREADME.txt  topic-news\n",
            "it-life-hack\tmovie-enter\tsmax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS7Nvnbs1JoD",
        "colab_type": "code",
        "outputId": "1d68e11f-08fb-42d3-9546-01670770297c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!ls ./text/sports-watch/ | head"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LICENSE.txt\n",
            "sports-watch-4597641.txt\n",
            "sports-watch-4601248.txt\n",
            "sports-watch-4604621.txt\n",
            "sports-watch-4609913.txt\n",
            "sports-watch-4612295.txt\n",
            "sports-watch-4623406.txt\n",
            "sports-watch-4623588.txt\n",
            "sports-watch-4627799.txt\n",
            "sports-watch-4628232.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_tqGDGpLFwo",
        "colab_type": "text"
      },
      "source": [
        "- １行目：記事のURL\n",
        "- ２行目：記事の日付\n",
        "- ３行目：記事のタイトル\n",
        "- ４行目以降：記事の本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7tj3Tv4Zi_w",
        "colab_type": "code",
        "outputId": "08322505-4bea-4448-91c4-b708dede08c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "!head ./text/sports-watch/sports-watch-4597641.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://news.livedoor.com/article/detail/4597641/\n",
            "2010-02-10T10:50:00+0900\n",
            "【Sports Watch】秋山成勲、メールで吉田に対戦迫った!?\n",
            "今月8日、都内ホテルでは、総合格闘家・吉田秀彦の引退試合興行「ASTRA」の開催が発表された。\n",
            "\n",
            "バルセロナ五輪柔道金メダリストとしての実績を引っさげ、2002年にプロ総合格闘家に転向。以後、数々の死闘を繰り広げてきた吉田。昨年大晦日のDynamite!!では、石井慧との金メダリスト対決を制し、4月に迎える引退試合の相手には、桜庭和志やまさかの朝青龍といった報道が駆け巡る中、“反骨の柔道王”秋山成勲が吉田にメールで対戦を迫っていたというのだ。\n",
            "\n",
            "会見翌日の9日に更新された秋山成勲オフィシャルブログでは、「吉田秀彦対秋山成勲」と題し、「常に憧れ目標にしてきた吉田先輩が引退。正直寂しい気持ちはありますが、ほんまにお疲れ様でした！引退試合はもちろん自分とやるでしょ！？」とストレートに書き綴りながらも、「さっき吉田先輩にメールで自分とやるでしょ？的なメールを打って、軽く流されましたが」と、実際に吉田へ対戦を打診をしていたことを明かした。\n",
            "\n",
            "もちろん、階級が違う上、秋山は米UFCを主戦場にしている現状、対戦することはまずない。それでも、我が道を行き、空気を一切読まない秋山だけに、案外本気に考えていた可能性もなきにしもあらず——。そんなブログの最後には、「ほんまに柔道から格闘技の道を作って頂いたパイオニアだと自分は思い尊敬してます！引退試合頑張ってください！」と吉田にエールを送る秋山であった。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykyozu5YLTEU",
        "colab_type": "code",
        "outputId": "9f3b66cd-7e2d-4634-d17c-be775293734c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls text/sports-watch | grep \".txt\" | wc -l"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXvZgvPZq0W",
        "colab_type": "text"
      },
      "source": [
        "## Pythonで文書分類を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQVVu-nhvwZb",
        "colab_type": "text"
      },
      "source": [
        "### データの前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzC3rBZRZxPR",
        "colab_type": "text"
      },
      "source": [
        "#### 利用するモジュールのimport\n",
        "- ファイルを読み込むためのglob\n",
        "- データ整形を行うためのpandas\n",
        "- 形態素解析器\n",
        "- scikit-learn\n",
        "  - CountVectorizer\n",
        "  - TFIDFモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCsLBcdLxhS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import re\n",
        "\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f71r2SASedn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LabelEncoderでどうしてもWarningが出るので、いったんWarningを非表示にする\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiy6UaMGaMlm",
        "colab_type": "text"
      },
      "source": [
        "#### 文書を読み込む\n",
        "カテゴリは9カテゴリ\n",
        "\n",
        "記事ファイルのフォーマットは以下であるため、これをタプル化する。\n",
        "\n",
        "- １行目：記事のURL\n",
        "- ２行目：記事の日付\n",
        "- ３行目：記事のタイトル\n",
        "- ４行目以降：記事の本文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIsT46VRaDlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = [\n",
        "    \"sports-watch\", \"topic-news\", \"dokujo-tsushin\", \"peachy\",\n",
        "    \"movie-enter\", \"kaden-channel\", \"livedoor-homme\", \"smax\",\n",
        "    \"it-life-hack\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyNpuGjcxhbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = []\n",
        "for category in categories:\n",
        "    for f in glob.glob(f\"./text/{category}/{category}*.txt\"):\n",
        "        # 1ファイルごとに処理\n",
        "        with open(f, \"r\") as fin:\n",
        "            # nextで1行取得する(__next__を呼ぶ)\n",
        "            url = next(fin).strip()\n",
        "            date = next(fin).strip()\n",
        "            title = next(fin).strip()\n",
        "            body = \"\\n\".join([line.strip() for line in fin if line.strip()])\n",
        "      \n",
        "        docs.append((category, url, date, title, body))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_akJlmVDv66",
        "colab_type": "code",
        "outputId": "c57da607-ae7f-4a5a-f90c-75937aa949af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "docs[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sports-watch',\n",
              " 'http://news.livedoor.com/article/detail/5402934/',\n",
              " '2011-03-10T13:30:00+0900',\n",
              " '【Sports Watch】日本代表・細貝、人気モデルと結婚を発表',\n",
              " 'アジアカップ・韓国戦では、本田圭佑が外したPKのこぼれ球をゴールに叩き込み、勝利の立役者となったサッカー日本代表・細貝萌。イケメン選手としても知られる細貝は、前橋育英高校卒業後から約6年間所属した浦和レッズを離れ、ドイツのブンデスリーガで新たな挑戦をはじめた。\\nそんな折、今月10日、細貝は人生のパートナーとして、人気モデル・中村明花さんとの結婚を自身のブログで発表した。\\n「これまでの間、お互いの仕事を支え合いながらお付き合いさせて頂いていました」と綴る細貝。「僕はサッカー選手として自分のリズムで生活を送っている中、明花さんは、時間がある限り美味しい手料理を作ってくれるなど、僕をサポートしてくれました。サポーターの皆様の温かい応援と共に、浦和レッズ在籍時には本当に有り難い存在でした」と明かし、ドイツ挑戦についても「明花さんも一番近くで僕の背中を押してくれました」と語っている。\\nまた、中村さんの公式ブログでは「私も日本で仕事があった為、今は別々に暮らしていますが、時期を見て私もドイツに向かおうと思っています」と綴り、ドイツでの新生活をスタートする旨が報告されつつ、「海外に住むなんて考えた事なかったけど…彼を好きになっちゃんたんだからしょうがない！！！笑」とも。\\n新たなパートナーを得た細貝、今後の躍進に益々期待が持てそうだ。')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlzplrODaw6k",
        "colab_type": "text"
      },
      "source": [
        "#### 取り扱いやすいデータフレーム形式に変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YhZOfWfxhf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(\n",
        "        docs,\n",
        "        columns=[\"category\", \"url\", \"date\", \"title\", \"body\"],\n",
        "        dtype=\"category\"\n",
        ")\n",
        "# 日付は日付型に変更（今回使うわけでは無い）\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu4oAeHwbBuR",
        "colab_type": "text"
      },
      "source": [
        "#### データの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJIfNTtfzAUy",
        "colab_type": "code",
        "outputId": "95421faa-c8f6-4821-a26c-47f56e272afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# 先頭行数行を表示\n",
        "df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>url</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5402934/</td>\n",
              "      <td>2011-03-10 13:30:00+09:00</td>\n",
              "      <td>【Sports Watch】日本代表・細貝、人気モデルと結婚を発表</td>\n",
              "      <td>アジアカップ・韓国戦では、本田圭佑が外したPKのこぼれ球をゴールに叩き込み、勝利の立役者とな...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6277612/</td>\n",
              "      <td>2012-02-14 11:30:00+09:00</td>\n",
              "      <td>金本知憲が復活へ「何だかんだいったヤツを見返してやりたい」</td>\n",
              "      <td>11日深夜放送、TBS「S1」では「反骨の43歳 金本知憲 復活へ知られざる激闘録」と題し、...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5737499/</td>\n",
              "      <td>2011-07-27 08:30:00+09:00</td>\n",
              "      <td>【Sports Watch】なでしこ岩清水、佐々木監督の暴露に「ふざけんなよ。マジムカつく」</td>\n",
              "      <td>24日放送、テレビ朝日「やべっちF.C.」初の90分スペシャルには、なでしこジャパンから7選...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5184767/</td>\n",
              "      <td>2010-12-04 11:00:00+09:00</td>\n",
              "      <td>【Sports Watch】ヤクルト身売り報道、球団広報は「一切の事実無根」</td>\n",
              "      <td>4日、日刊スポーツは、ヤクルトスワローズがアメーバブログの運営でもお馴染み、サイバーエージェ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5322376/</td>\n",
              "      <td>2011-02-06 07:30:00+09:00</td>\n",
              "      <td>【Sports Watch】八百長調査委員に、たけし「役に立たねーじゃねーか」</td>\n",
              "      <td>5日、大相撲八百長問題の調査を行う日本相撲協会の特別調査委員会が記者会見を行うと、早稲田大学...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       category  ...                                               body\n",
              "0  sports-watch  ...  アジアカップ・韓国戦では、本田圭佑が外したPKのこぼれ球をゴールに叩き込み、勝利の立役者とな...\n",
              "1  sports-watch  ...  11日深夜放送、TBS「S1」では「反骨の43歳 金本知憲 復活へ知られざる激闘録」と題し、...\n",
              "2  sports-watch  ...  24日放送、テレビ朝日「やべっちF.C.」初の90分スペシャルには、なでしこジャパンから7選...\n",
              "3  sports-watch  ...  4日、日刊スポーツは、ヤクルトスワローズがアメーバブログの運営でもお馴染み、サイバーエージェ...\n",
              "4  sports-watch  ...  5日、大相撲八百長問題の調査を行う日本相撲協会の特別調査委員会が記者会見を行うと、早稲田大学...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34zYL8AP1lj5",
        "colab_type": "code",
        "outputId": "9868eefd-0bca-4f04-9f98-973164c79724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# それぞれの要素数を数え上げる\n",
        "df.category.value_counts()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sports-watch      900\n",
              "smax              870\n",
              "movie-enter       870\n",
              "it-life-hack      870\n",
              "dokujo-tsushin    870\n",
              "kaden-channel     864\n",
              "peachy            842\n",
              "topic-news        770\n",
              "livedoor-homme    511\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-GY5j6EbUpE",
        "colab_type": "text"
      },
      "source": [
        "#### 単語分割\n",
        "MeCabで分かち書きを行う処理を関数化する。\n",
        "\n",
        "DataFrameに分かち書き済みのテキストを格納する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RIl32yKkyYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "def parse_to_wakati(text):\n",
        "    # wakatiモードのMeCabのparseは、文字列を返す\n",
        "    return tagger.parse(text).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JNv3M8zik5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dfのbody_wakatiという列に対して、bodyを分かち書きしたものを代入する\n",
        "df = df.assign(body_wakati=df.body.apply(parse_to_wakati))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQkXCZXIk_0C",
        "colab_type": "code",
        "outputId": "1620cb80-b16e-4bda-89b2-cf654f7b4112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>url</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>body_wakati</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5402934/</td>\n",
              "      <td>2011-03-10 13:30:00+09:00</td>\n",
              "      <td>【Sports Watch】日本代表・細貝、人気モデルと結婚を発表</td>\n",
              "      <td>アジアカップ・韓国戦では、本田圭佑が外したPKのこぼれ球をゴールに叩き込み、勝利の立役者とな...</td>\n",
              "      <td>アジア カップ ・ 韓国 戦 で は 、 本田 圭 佑 が 外し た PK の こぼれ 球 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6277612/</td>\n",
              "      <td>2012-02-14 11:30:00+09:00</td>\n",
              "      <td>金本知憲が復活へ「何だかんだいったヤツを見返してやりたい」</td>\n",
              "      <td>11日深夜放送、TBS「S1」では「反骨の43歳 金本知憲 復活へ知られざる激闘録」と題し、...</td>\n",
              "      <td>11 日 深夜 放送 、 TBS 「 S 1 」 で は 「 反骨 の 43 歳 金本 知 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5737499/</td>\n",
              "      <td>2011-07-27 08:30:00+09:00</td>\n",
              "      <td>【Sports Watch】なでしこ岩清水、佐々木監督の暴露に「ふざけんなよ。マジムカつく」</td>\n",
              "      <td>24日放送、テレビ朝日「やべっちF.C.」初の90分スペシャルには、なでしこジャパンから7選...</td>\n",
              "      <td>24 日 放送 、 テレビ朝日 「 や べっち F . C .」 初 の 90 分 スペシャ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5184767/</td>\n",
              "      <td>2010-12-04 11:00:00+09:00</td>\n",
              "      <td>【Sports Watch】ヤクルト身売り報道、球団広報は「一切の事実無根」</td>\n",
              "      <td>4日、日刊スポーツは、ヤクルトスワローズがアメーバブログの運営でもお馴染み、サイバーエージェ...</td>\n",
              "      <td>4 日 、 日刊 スポーツ は 、 ヤクルトスワローズ が アメーバブログ の 運営 で も...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sports-watch</td>\n",
              "      <td>http://news.livedoor.com/article/detail/5322376/</td>\n",
              "      <td>2011-02-06 07:30:00+09:00</td>\n",
              "      <td>【Sports Watch】八百長調査委員に、たけし「役に立たねーじゃねーか」</td>\n",
              "      <td>5日、大相撲八百長問題の調査を行う日本相撲協会の特別調査委員会が記者会見を行うと、早稲田大学...</td>\n",
              "      <td>5 日 、 大相撲 八百長 問題 の 調査 を 行う 日本 相撲 協会 の 特別 調査 委員...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       category  ...                                        body_wakati\n",
              "0  sports-watch  ...  アジア カップ ・ 韓国 戦 で は 、 本田 圭 佑 が 外し た PK の こぼれ 球 ...\n",
              "1  sports-watch  ...  11 日 深夜 放送 、 TBS 「 S 1 」 で は 「 反骨 の 43 歳 金本 知 ...\n",
              "2  sports-watch  ...  24 日 放送 、 テレビ朝日 「 や べっち F . C .」 初 の 90 分 スペシャ...\n",
              "3  sports-watch  ...  4 日 、 日刊 スポーツ は 、 ヤクルトスワローズ が アメーバブログ の 運営 で も...\n",
              "4  sports-watch  ...  5 日 、 大相撲 八百長 問題 の 調査 を 行う 日本 相撲 協会 の 特別 調査 委員...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i606H7B7E2lF",
        "colab_type": "code",
        "outputId": "a34ec4c6-6a33-4412-8d96-ee1ef5b655c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "df.body_wakati.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    アジア カップ ・ 韓国 戦 で は 、 本田 圭 佑 が 外し た PK の こぼれ 球 ...\n",
              "1    11 日 深夜 放送 、 TBS 「 S 1 」 で は 「 反骨 の 43 歳 金本 知 ...\n",
              "2    24 日 放送 、 テレビ朝日 「 や べっち F . C .」 初 の 90 分 スペシャ...\n",
              "3    4 日 、 日刊 スポーツ は 、 ヤクルトスワローズ が アメーバブログ の 運営 で も...\n",
              "4    5 日 、 大相撲 八百長 問題 の 調査 を 行う 日本 相撲 協会 の 特別 調査 委員...\n",
              "Name: body_wakati, dtype: category\n",
              "Categories (7359, object): [\" ミスター \" こと 長嶋 茂雄 ・ 終身 名誉 監督 の 発言 が 物議 を かもし て..., \" 合コン 総研 アナリスト \" の 水谷 麻衣 さん に 聞く 合コン の 極意 。 有名...,\n",
              "                            \" 女のコ の ため の 日本 最大 級 ファッションフェスタ \"『 東京 ガールズコレクシ..., \" 女のコ の ため の 日本 最大 級 ファッションフェスタ \"『 東京 ガールズコレクシ...,\n",
              "                            ..., ＮＴＴドコモ が 、 今年 の １２月 を めど に 、 イギリス の ボーダフォン 法人 ...,\n",
              "                            ＳＦ 小説 の 巨匠 ロバート ・ Ａ ・ ハインライン の 傑作 『 宇宙 の 戦士 』 ..., ＷＢＡ 世界 バンタム 級 王者 ・ 亀田 興 毅 の ４ 度目 の 防衛 戦 が 、 ４月...,\n",
              "                            ｉＰｈｏｎｅ ５ について 、 様々 な 憶測 が 飛び交っ て いる 。 早く 詳細 を ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mgNaulMd50q",
        "colab_type": "text"
      },
      "source": [
        "#### ルールベースのためのラベルのエンコード\n",
        "scikit-learnでは予測値のラベルは数値にエンコードする必要がある。\n",
        "\n",
        "まず、ルールを書くために、予測するラベルをエンコードしておく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlEmT4go1d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ラベルエンコーダは、ラベルを数値に変換する\n",
        "le = LabelEncoder()\n",
        "\n",
        "# ラベルをエンコードし、エンコード結果をyに代入する\n",
        "y = le.fit_transform(df.category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht_dsNIjFSjn",
        "colab_type": "code",
        "outputId": "2fa18da4-2da6-4a1f-9bda-daaff19b1e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 7, 7, 7, 7, 7, 7, 7, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx2Tu8_VqKNR",
        "colab_type": "code",
        "outputId": "e462ac56-3d73-4696-eedf-363c1818ef22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# ラベルエンコーダがエンコードしたクラスの種類を表示\n",
        "print(le.classes_)\n",
        "\n",
        "# sports-watchクラスが、何にエンコードされたか確認\n",
        "print(le.transform([\"sports-watch\"]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dokujo-tsushin' 'it-life-hack' 'kaden-channel' 'livedoor-homme'\n",
            " 'movie-enter' 'peachy' 'smax' 'sports-watch' 'topic-news']\n",
            "[7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR_kxj2xtcjt",
        "colab_type": "text"
      },
      "source": [
        "#### 学習とテストに分けて、学習と推定を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPV9HyvltCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                      df.body_wakati,  # 入力\n",
        "                                      y, # 正解ラベル\n",
        "                                      test_size=0.2, # テストデータのサイズ（全体の何割か）\n",
        "                                      random_state=42, # シャッフルしたときの乱数の種を固定\n",
        "                                      shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhwqC8fntaAd",
        "colab_type": "text"
      },
      "source": [
        "### ルールベース"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8s4iMasZvee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNbrYdd9v7xV",
        "colab_type": "text"
      },
      "source": [
        "#### ルールベース分類器の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farluH7npYbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scikit-learnのBaseEstimatorとTransformerMixinを継承することで、scikit-learn互換のクラスを作りやすくする\n",
        "class RulebasedEstimator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, label_encoder):\n",
        "        self.le = label_encoder\n",
        "  \n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"ルールを記述\"\"\"\n",
        "        result = []\n",
        "        for text in X:\n",
        "            pred = 0\n",
        "            if re.search(r\"(スポーツ|サッカー)\", text):\n",
        "                pred = self.le.transform([\"sports-watch\"])[0]\n",
        "            elif re.search(r\"(独女|悩み|ブライド|サプライズ)\", text):\n",
        "                pred = self.le.transform([\"dokujo-tsushin\"])[0]\n",
        "            elif re.search(r\"(Mac|PC|IT|インテル|SSD|CPU)\", text):\n",
        "                pred = self.le.transform([\"it-life-hack\"])[0]\n",
        "            elif re.search(r\"(電力|冷蔵庫|扇風機|家電|熱中症)\", text):\n",
        "                pred = self.le.transform([\"kaden-channel\"])[0]\n",
        "            elif re.search(r\"(店|店舗|マラソン|スポーツ)\", text):\n",
        "                pred = self.le.transform([\"livedoor-homme\"])[0]\n",
        "            elif re.search(r\"(映画|芸能|リアクション|公開)\", text):\n",
        "                pred = self.le.transform([\"movie-enter\"])[0]\n",
        "            elif re.search(r\"(食べ物|菓子|ごはん|ワイン|カフェ)\", text):\n",
        "                pred = self.le.transform([\"peachy\"])[0]\n",
        "            elif re.search(r\"(ゲーム|スマホ)\", text):\n",
        "                pred = self.le.transform([\"smax\"])[0]\n",
        "            elif re.search(r\"(メダル|プレー)\", text):\n",
        "                pred = self.le.transform([\"sports-watch\"])[0]\n",
        "            elif re.search(r\"(テレビ|ジャーナリスト)\", text):\n",
        "                pred = self.le.transform([\"topic-news\"])[0]\n",
        "\n",
        "            result.append(pred)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4vEBgKywJSo",
        "colab_type": "text"
      },
      "source": [
        "#### ルールベースによる分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Z-dRXwrY5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rulebased = RulebasedEstimator(label_encoder=le)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7gdySdxretX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rulebased_pred = rulebased.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA-gtmRkrhPX",
        "colab_type": "text"
      },
      "source": [
        "####ルールベースの評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epmz9x1puFsg",
        "colab_type": "code",
        "outputId": "b955c771-5793-4624-f32b-9ae82d7e854e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "print(classification_report(y_test, rulebased_pred, target_names=le.classes_))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.19      0.48      0.27       176\n",
            "  it-life-hack       0.44      0.58      0.50       139\n",
            " kaden-channel       0.62      0.19      0.29       178\n",
            "livedoor-homme       0.15      0.25      0.19        83\n",
            "   movie-enter       0.54      0.81      0.64       182\n",
            "        peachy       0.44      0.08      0.14       173\n",
            "          smax       0.26      0.10      0.15       182\n",
            "  sports-watch       0.50      0.50      0.50       191\n",
            "    topic-news       0.23      0.11      0.15       170\n",
            "\n",
            "      accuracy                           0.35      1474\n",
            "     macro avg       0.37      0.34      0.31      1474\n",
            "  weighted avg       0.39      0.35      0.32      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C9Crxkl0X47",
        "colab_type": "text"
      },
      "source": [
        "  | 実際は正 | 実際は負\n",
        "--- | -- | --\n",
        "予測は正 | True Positive | False Positive\n",
        "予測は負 | False Negative | True Negative\n",
        "\n",
        "- 適合率(Precision)：正と予測したうち、実際に正であるものの割合\n",
        "\n",
        "$$ Precision = \\frac{True Positive}{True Positive + False Positive} $$\n",
        "\n",
        "- 再現率(Recall)：実際に正であるもののうち、正と予測されたものの割合\n",
        "\n",
        "$$ Recall = \\frac{True Positive}{True Positive + False Negative} $$\n",
        "\n",
        "- F値(F-measure)：適合率と再現率の調和平均\n",
        "\n",
        "$$ F-measure = \\frac{2 \\cdot Recall \\cdot Precision}{Recall + Precision} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvxVw_ihkgqC",
        "colab_type": "text"
      },
      "source": [
        "### 多変数ベルヌーイモデルを用いたナイーブベイズ分類器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2I5sWuQOLXb",
        "colab_type": "text"
      },
      "source": [
        "データの入力から推定までのパイプラインを作成する。\n",
        "\n",
        "単語の頻度を数え上げ、それを分類器が学習するというパイプラインを作る。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uRJTGFCeLH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_clf = Pipeline([\n",
        "    (\"count_vec\", CountVectorizer()),\n",
        "    (\"clf\", MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqymrAwwOoxU",
        "colab_type": "text"
      },
      "source": [
        "作成したパイプラインに学習データを流し込む。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWpQru4XvmVY",
        "colab_type": "code",
        "outputId": "7089b386-9da5-4037-deef-34cecd4bca9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "text_clf.fit(X_train, y_train)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('count_vec',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS6_TeZDOx1M",
        "colab_type": "text"
      },
      "source": [
        "テストデータを入力し、分類する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTJ1i-Oqndjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = text_clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWRDBZWLO4tg",
        "colab_type": "text"
      },
      "source": [
        "評価する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnWf6krUnivg",
        "colab_type": "code",
        "outputId": "a0b7567c-e185-4a7a-c856-6591df6d0078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.77      0.90      0.83       176\n",
            "  it-life-hack       0.91      0.91      0.91       139\n",
            " kaden-channel       0.95      0.85      0.90       178\n",
            "livedoor-homme       0.86      0.83      0.85        83\n",
            "   movie-enter       0.92      0.98      0.95       182\n",
            "        peachy       0.86      0.74      0.80       173\n",
            "          smax       0.94      0.99      0.97       182\n",
            "  sports-watch       0.97      0.96      0.97       191\n",
            "    topic-news       0.94      0.91      0.92       170\n",
            "\n",
            "      accuracy                           0.90      1474\n",
            "     macro avg       0.90      0.90      0.90      1474\n",
            "  weighted avg       0.91      0.90      0.90      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HogQFsVcOvjK",
        "colab_type": "code",
        "outputId": "72dca628-eb10-4337-afdc-904e63abe126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(confusion_matrix(y_test, pred, labels=le.transform(le.classes_)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[158   0   0   1   5  11   0   1   0]\n",
            " [  5 126   1   0   0   2   3   1   1]\n",
            " [  2   9 152   3   1   2   4   1   4]\n",
            " [  2   0   4  69   3   5   0   0   0]\n",
            " [  2   0   0   0 179   1   0   0   0]\n",
            " [ 30   0   2   5   5 128   3   0   0]\n",
            " [  0   1   0   0   0   0 181   0   0]\n",
            " [  1   0   0   1   0   0   0 184   5]\n",
            " [  6   3   1   1   1   0   1   3 154]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylmqJHkicQOs",
        "colab_type": "text"
      },
      "source": [
        "#### 任意のテキストを入力して解析する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMH8NqM4PHko",
        "colab_type": "code",
        "outputId": "87a420dd-7196-40bf-9deb-225411deb14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "original_text = \"あの「Orange is the new black」のシーズン６が7月28日についにNetflixに上陸！\"\n",
        "\n",
        "wakati_text = parse_to_wakati(original_text)\n",
        "print(le.inverse_transform(text_clf.predict([wakati_text]))[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movie-enter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbsKrK8hhLM",
        "colab_type": "text"
      },
      "source": [
        "#### 間違った例を見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AepYl-9re2mF",
        "colab_type": "code",
        "outputId": "16000284-65e4-472b-bdfa-d9b3c7a484e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "idx = y_test != pred\n",
        "for text, t, p in zip(X_test[idx][:5], y_test[idx][:5], pred[idx][:5]):\n",
        "    print(\"予測：{}\\n推定:{}\".format(le.inverse_transform(t), le.inverse_transform(p)))\n",
        "    print(text)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-12b62e9fda07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"予測：{}\\n推定:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape ()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4JVg7r5zVo2",
        "colab_type": "text"
      },
      "source": [
        "### Bernoulliのナイーブベイズ分類器\n",
        "頻度の数え上げを行い、ナイーブベイズ分類器を学習する。\n",
        "\n",
        "$$ P(x_{i} | y) = P(i | y)x_{i} + (1-P(i|y))(1-x_{i})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNDUE8NWzbMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bernoulli_clf = Pipeline([\n",
        "    (\"count_vec\", CountVectorizer()),\n",
        "    (\"clf\", BernoulliNB()),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19HBvy8ir1WS",
        "colab_type": "text"
      },
      "source": [
        "作成したパイプラインに基づき学習する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVERMnllz_4l",
        "colab_type": "code",
        "outputId": "cddff8a1-6297-4d3b-fe84-3e075c16cfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "bernoulli_clf.fit(X_train, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('count_vec',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
              "                             fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-LF9LRor5_c",
        "colab_type": "text"
      },
      "source": [
        "学習したパラメータを用いて、クラス推定を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOkIEEb1Gyl",
        "colab_type": "code",
        "outputId": "19b6db2a-bf87-47e6-99ca-281e19fd6733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "pred = bernoulli_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.81      0.90      0.85       176\n",
            "  it-life-hack       0.93      0.89      0.91       139\n",
            " kaden-channel       0.83      0.92      0.87       178\n",
            "livedoor-homme       0.91      0.39      0.54        83\n",
            "   movie-enter       0.93      0.91      0.92       182\n",
            "        peachy       0.78      0.73      0.76       173\n",
            "          smax       0.99      0.98      0.99       182\n",
            "  sports-watch       0.83      0.99      0.90       191\n",
            "    topic-news       0.95      0.91      0.93       170\n",
            "\n",
            "      accuracy                           0.88      1474\n",
            "     macro avg       0.89      0.85      0.85      1474\n",
            "  weighted avg       0.88      0.88      0.87      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXIpmdtxkuE9",
        "colab_type": "text"
      },
      "source": [
        "### 線形SVMによる分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0pTo9SsnS8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZg2iRga1q84",
        "colab_type": "code",
        "outputId": "6b1f8c46-ed93-4fd0-9312-063b021f6037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "svm_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", LinearSVC()),\n",
        "])\n",
        "\n",
        "svm_clf.fit(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ctvWws13q-",
        "colab_type": "code",
        "outputId": "f621d61a-294d-4c85-b3a8-f0757f87cf92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "pred = svm_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.90      0.93      0.91       176\n",
            "  it-life-hack       0.96      0.98      0.97       139\n",
            " kaden-channel       0.97      0.93      0.95       178\n",
            "livedoor-homme       0.92      0.86      0.89        83\n",
            "   movie-enter       0.95      0.99      0.97       182\n",
            "        peachy       0.91      0.88      0.90       173\n",
            "          smax       0.98      0.99      0.99       182\n",
            "  sports-watch       0.94      0.98      0.96       191\n",
            "    topic-news       0.98      0.94      0.96       170\n",
            "\n",
            "      accuracy                           0.95      1474\n",
            "     macro avg       0.95      0.94      0.94      1474\n",
            "  weighted avg       0.95      0.95      0.95      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKHu94aLutbU",
        "colab_type": "text"
      },
      "source": [
        "### ランダムフォレストによる分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUrG4aSx2XRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP6QI82M2rX8",
        "colab_type": "code",
        "outputId": "49663cfd-6615-4154-a72d-74e0a76b0ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "rf_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", RandomForestClassifier()),\n",
        "])\n",
        "\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RapifuM72v1l",
        "colab_type": "code",
        "outputId": "97e9cc7e-d567-41d7-f3b8-d41620dd5075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "pred = rf_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.79      0.91      0.85       176\n",
            "  it-life-hack       0.94      0.94      0.94       139\n",
            " kaden-channel       0.91      0.87      0.89       178\n",
            "livedoor-homme       0.88      0.43      0.58        83\n",
            "   movie-enter       0.92      0.96      0.94       182\n",
            "        peachy       0.83      0.81      0.82       173\n",
            "          smax       0.98      0.99      0.99       182\n",
            "  sports-watch       0.88      0.97      0.92       191\n",
            "    topic-news       0.94      0.92      0.93       170\n",
            "\n",
            "      accuracy                           0.89      1474\n",
            "     macro avg       0.90      0.87      0.87      1474\n",
            "  weighted avg       0.90      0.89      0.89      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VUGpQf4iI3I",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7WUy0TfOicba"
      },
      "source": [
        "### XGBoostによる分類器\n",
        "学習に数分時間が必要"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCjA-rCXi6dQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BpNKyb_kNwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "f76aa26d-1ec6-4de7-9d37-f601dd5f355a"
      },
      "source": [
        "xgb_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", xgb.XGBClassifier()),\n",
        "])\n",
        "\n",
        "xgb_clf.fit(X_train, y_train)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlveFvaMnjgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "523bf735-2774-40b5-be91-ec741b731de1"
      },
      "source": [
        "pred = xgb_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.88      0.90      0.89       176\n",
            "  it-life-hack       0.95      0.96      0.96       139\n",
            " kaden-channel       0.96      0.92      0.94       178\n",
            "livedoor-homme       0.81      0.76      0.78        83\n",
            "   movie-enter       0.94      0.96      0.95       182\n",
            "        peachy       0.83      0.88      0.85       173\n",
            "          smax       0.99      0.98      0.99       182\n",
            "  sports-watch       0.92      0.96      0.94       191\n",
            "    topic-news       0.98      0.91      0.95       170\n",
            "\n",
            "      accuracy                           0.92      1474\n",
            "     macro avg       0.92      0.91      0.92      1474\n",
            "  weighted avg       0.93      0.92      0.92      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4UfhP_5ntC4",
        "colab_type": "text"
      },
      "source": [
        "### NGBoostによる分類器\n",
        "学習にxgboostのN倍時間が必要\n",
        "実際には20~30分程度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3D0pRzRnv-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ngboost as ngb\n",
        "from ngboost.distns import k_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V85S-ejn1dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "89ae0f67-d0d3-42db-a4ca-4018417ab597"
      },
      "source": [
        "#k_categoricalの値は分類ラベル数と同じにする必要がある\n",
        "ngb_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", ngb.NGBClassifier(Dist=k_categorical(9))),\n",
        "])\n",
        "\n",
        "ngb_clf.fit(X_train, y_train)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[iter 0] loss=2.1875 val_loss=0.0000 scale=0.5000 norm=5.4142\n",
            "[iter 100] loss=0.8331 val_loss=0.0000 scale=2.0000 norm=7.0513\n",
            "[iter 200] loss=0.5230 val_loss=0.0000 scale=4.0000 norm=10.8217\n",
            "[iter 300] loss=0.4314 val_loss=0.0000 scale=1.0000 norm=2.4859\n",
            "[iter 400] loss=0.4042 val_loss=0.0000 scale=1.0000 norm=2.4305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='...\n",
              "                                                          presort='deprecated',\n",
              "                                                          random_state=None,\n",
              "                                                          splitter='best'),\n",
              "                               Dist=<class 'ngboost.distns.categorical.k_categorical.<locals>.Categorical'>,\n",
              "                               Score=<class 'ngboost.scores.LogScore'>,\n",
              "                               learning_rate=0.01, minibatch_frac=1.0,\n",
              "                               n_estimators=500, natural_gradient=True,\n",
              "                               random_state=RandomState(MT19937) at 0x7F2977424780,\n",
              "                               tol=0.0001, verbose=True, verbose_eval=100))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpP7YUVRn5gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#学習モデル保存\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF6B4_GG1jDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "214358b8-36aa-4243-c8a8-ef3e459417d8"
      },
      "source": [
        "pickle.dump(ngb_clf, open(\"model_ngb_best.pkl\", \"wb\"))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-a22d3753e3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngb_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_ngb_best.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'k_categorical.<locals>.Categorical'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uHroqD41LEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "5eda111e-988b-49fc-f56b-240d0c2a3331"
      },
      "source": [
        "#分類結果推定\n",
        "pred = ngb_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.88      0.69      0.77       176\n",
            "  it-life-hack       0.74      0.88      0.80       139\n",
            " kaden-channel       0.87      0.80      0.83       178\n",
            "livedoor-homme       0.78      0.52      0.62        83\n",
            "   movie-enter       0.87      0.92      0.90       182\n",
            "        peachy       0.57      0.84      0.68       173\n",
            "          smax       0.99      0.98      0.99       182\n",
            "  sports-watch       0.92      0.84      0.88       191\n",
            "    topic-news       0.95      0.84      0.89       170\n",
            "\n",
            "      accuracy                           0.83      1474\n",
            "     macro avg       0.84      0.81      0.82      1474\n",
            "  weighted avg       0.85      0.83      0.83      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytAdfRgyuzgP",
        "colab_type": "text"
      },
      "source": [
        "### 多層パーセプトロンによる分類器\n",
        "\n",
        "学習に数分時間が必要"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2yrc2ru16ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZdH-_mN2P0t",
        "colab_type": "code",
        "outputId": "003de454-c06b-4ea4-e4ff-f15547d38cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "mlp_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MLPClassifier()),\n",
        "])\n",
        "\n",
        "mlp_clf.fit(X_train, y_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='...\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(100,),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='adam',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyj2aCmy2UHg",
        "colab_type": "code",
        "outputId": "3bccef7d-6b0d-4108-fe8a-058633bd6285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "pred = mlp_clf.predict(X_test)\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.90      0.92      0.91       176\n",
            "  it-life-hack       0.96      0.96      0.96       139\n",
            " kaden-channel       0.98      0.93      0.95       178\n",
            "livedoor-homme       0.94      0.87      0.90        83\n",
            "   movie-enter       0.94      0.98      0.96       182\n",
            "        peachy       0.90      0.88      0.89       173\n",
            "          smax       0.97      0.99      0.98       182\n",
            "  sports-watch       0.95      0.98      0.97       191\n",
            "    topic-news       0.97      0.94      0.96       170\n",
            "\n",
            "      accuracy                           0.94      1474\n",
            "     macro avg       0.94      0.94      0.94      1474\n",
            "  weighted avg       0.94      0.94      0.94      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm4wV_bLyqNJ",
        "colab_type": "text"
      },
      "source": [
        "### 多変数ベルヌーイモデルをnumpyで実装\n",
        "まだfor文があり、不完全な実装で動作が遅いです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Vmo1CDvnEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from scipy.sparse import lil_matrix, csr_matrix\n",
        "\n",
        "\n",
        "class NaiveBayes(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.vocabularies = None\n",
        "        self.categories = None\n",
        "        self.category_count = None\n",
        "        self.category_word_occurence = None\n",
        "        self.denominator = {}\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.vocabularies = np.unique(X)\n",
        "        self.categories, self.category_count = np.unique(y, return_counts=True)\n",
        "        \n",
        "        self.category_word_occurrence = lil_matrix((self.categories.shape[0], X.shape[1]))\n",
        "        for c in self.categories:\n",
        "            _y = y[y == c]\n",
        "            _X = X[y == c]\n",
        "            self.category_word_occurrence[c] = np.sum(_X, axis=0)\n",
        "        self.category_word_occurrence = self.category_word_occurrence.tocsr()\n",
        "        \n",
        "        # P(word | cat)の分母 Σ |(cat, word)| + |V|\n",
        "        for cat in self.categories:\n",
        "            self.denominator[cat] = np.sum(self.category_word_occurrence[cat]) + len(self.vocabularies)\n",
        "    \n",
        "    def word_prob(self, word, category):\n",
        "        \"\"\"P(word|cat)\"\"\"\n",
        "        return (self.category_word_occurrence[category, word]+1) / self.denominator[category]\n",
        "    \n",
        "    def score(self, doc, cat):\n",
        "        \"\"\"P(doc|cat)\"\"\"\n",
        "        sc = np.log(self.category_count[cat] / self.category_count.sum())\n",
        "        for word in doc.nonzero()[1]:\n",
        "            sc += np.log(self.word_prob(word, cat))\n",
        "        return sc\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict(doc) for doc in X])\n",
        "    \n",
        "    def _predict(self, doc):\n",
        "        \"\"\"P(cat|doc)\"\"\"\n",
        "        return np.argmax(np.array([self.score(doc, cat) for cat in self.categories]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P501PNDz0TEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTMLZ5Cz0Oo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_clf = NaiveBayes()\n",
        "nb_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDATXSGjc_Dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "eba4b1b6-4ce1-4e23-96b7-6e4295b01b9e"
      },
      "source": [
        "pred = nb_clf.predict(vectorizer.transform(X_test))\n",
        "print(classification_report(y_test, pred, target_names=le.classes_))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.86      0.89      0.87       176\n",
            "  it-life-hack       0.94      0.86      0.90       139\n",
            " kaden-channel       0.93      0.91      0.92       178\n",
            "livedoor-homme       0.73      0.83      0.78        83\n",
            "   movie-enter       0.93      0.97      0.95       182\n",
            "        peachy       0.85      0.74      0.79       173\n",
            "          smax       0.97      0.95      0.96       182\n",
            "  sports-watch       0.94      0.94      0.94       191\n",
            "    topic-news       0.89      0.96      0.92       170\n",
            "\n",
            "      accuracy                           0.90      1474\n",
            "     macro avg       0.89      0.90      0.89      1474\n",
            "  weighted avg       0.90      0.90      0.90      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCg_59jbeGHP",
        "colab_type": "text"
      },
      "source": [
        "## ルールベースの改善をしてみよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htb1LzvQOLPH",
        "colab_type": "code",
        "outputId": "7542ed64-26aa-4d83-ac0a-a09b81b87553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "df.query(\"category == 'smax'\").head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>url</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>body_wakati</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5627</th>\n",
              "      <td>smax</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6814359/</td>\n",
              "      <td>2012-08-01 20:55:00+09:00</td>\n",
              "      <td>本日発売開始！NTTドコモ向け簡単操作のシニア層向けスマホ「らくらくスマートフォン F-12...</td>\n",
              "      <td>らくらくスマートフォン F-12Dの画面キャプチャの方法を紹介！\\n本日1日（水）にNTTド...</td>\n",
              "      <td>らくらく スマート フォン F - 12 D の 画面 キャプチャ の 方法 を 紹介 ！ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5628</th>\n",
              "      <td>smax</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6826557/</td>\n",
              "      <td>2012-08-05 21:55:00+09:00</td>\n",
              "      <td>【最近のオススメ「Androidアプリ」特集：2012年7月30日〜8月5日編】</td>\n",
              "      <td>2012年7月30日〜8月5日に紹介したAndroidアプリ！\\n先週はNTTドコモ向け「ら...</td>\n",
              "      <td>2012 年 7 月 30 日 〜 8 月 5 日 に 紹介 し た Android アプリ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5629</th>\n",
              "      <td>smax</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6578513/</td>\n",
              "      <td>2012-05-21 09:55:00+09:00</td>\n",
              "      <td>モバイルプロジェクト・アワード2012の審査結果が発表！GALAXY Noteがハードウェア...</td>\n",
              "      <td>モバイルハードウェア部門最優秀賞をGALAXY Noteが受賞！\\nモバイル・コンテンツ・フ...</td>\n",
              "      <td>モバイル ハードウェア 部門 最優秀 賞 を GALAXY Note が 受賞 ！ モバイル...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5630</th>\n",
              "      <td>smax</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6872644/</td>\n",
              "      <td>2012-08-21 09:55:00+09:00</td>\n",
              "      <td>iOSにもガラパゴスがやってきた！Appleにはない電子書籍の自由化「電子書籍 GALAPA...</td>\n",
              "      <td>iPhone、iPadでもGALAPAGOS！\\n昨年、シャープ製電子書籍端末やスマートフォ...</td>\n",
              "      <td>iPhone 、 iPad で も GALAPAGOS ！ 昨年 、 シャープ 製 電子 書...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5631</th>\n",
              "      <td>smax</td>\n",
              "      <td>http://news.livedoor.com/article/detail/6601757/</td>\n",
              "      <td>2012-05-28 13:55:00+09:00</td>\n",
              "      <td>auスマートフォン「HTC J ISW13HT」のICカードロックがない！USIMカードを差...</td>\n",
              "      <td>レベル2ロックがかかってない！\\nau向けに先週25日（金）に発売開始したAndroidスマ...</td>\n",
              "      <td>レベル 2 ロック が かかっ て ない ！ au 向け に 先週 25 日 （ 金 ） に...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     category  ...                                        body_wakati\n",
              "5627     smax  ...  らくらく スマート フォン F - 12 D の 画面 キャプチャ の 方法 を 紹介 ！ ...\n",
              "5628     smax  ...  2012 年 7 月 30 日 〜 8 月 5 日 に 紹介 し た Android アプリ...\n",
              "5629     smax  ...  モバイル ハードウェア 部門 最優秀 賞 を GALAXY Note が 受賞 ！ モバイル...\n",
              "5630     smax  ...  iPhone 、 iPad で も GALAPAGOS ！ 昨年 、 シャープ 製 電子 書...\n",
              "5631     smax  ...  レベル 2 ロック が かかっ て ない ！ au 向け に 先週 25 日 （ 金 ） に...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrD4vKIqSNqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scikit-learnのBaseEstimatorとTransformerMixinを継承することで、scikit-learn互換のクラスを作りやすくする\n",
        "class RulebasedEstimator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, label_encoder):\n",
        "        self.le = label_encoder\n",
        "  \n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"ルールを記述\"\"\"\n",
        "        result = []\n",
        "        for text in X:\n",
        "            pred = 0\n",
        "            if re.search(r\"(スポーツ|サッカー)\", text):\n",
        "                pred = self.le.transform([\"sports-watch\"])[0]\n",
        "            elif re.search(r\"(独女|悩み|ブライド|サプライズ)\", text):\n",
        "                pred = self.le.transform([\"dokujo-tsushin\"])[0]\n",
        "            elif re.search(r\"(Mac|PC|IT|インテル|SSD|CPU)\", text):\n",
        "                pred = self.le.transform([\"it-life-hack\"])[0]\n",
        "            elif re.search(r\"(電力|冷蔵庫|扇風機|家電|熱中症)\", text):\n",
        "                pred = self.le.transform([\"kaden-channel\"])[0]\n",
        "            elif re.search(r\"(店|店舗|マラソン|スポーツ)\", text):\n",
        "                pred = self.le.transform([\"livedoor-homme\"])[0]\n",
        "            elif re.search(r\"(映画|芸能|リアクション|公開)\", text):\n",
        "                pred = self.le.transform([\"movie-enter\"])[0]\n",
        "            elif re.search(r\"(食べ物|菓子|ごはん|ワイン|カフェ)\", text):\n",
        "                pred = self.le.transform([\"peachy\"])[0]\n",
        "            elif re.search(r\"(ゲーム|スマホ)\", text):\n",
        "                pred = self.le.transform([\"smax\"])[0]\n",
        "            elif re.search(r\"(メダル|プレー)\", text):\n",
        "                pred = self.le.transform([\"sports-watch\"])[0]\n",
        "            elif re.search(r\"(テレビ|ジャーナリスト)\", text):\n",
        "                pred = self.le.transform([\"topic-news\"])[0]\n",
        "\n",
        "            result.append(pred)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYTL7vWredUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "bd565f07-d7af-4f71-aac4-7d0e56d1da7f"
      },
      "source": [
        "rulebased = RulebasedEstimator(label_encoder=le)\n",
        "rulebased_pred = rulebased.predict(X_test)\n",
        "print(classification_report(y_test, rulebased_pred, target_names=le.classes_))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "dokujo-tsushin       0.19      0.48      0.27       176\n",
            "  it-life-hack       0.44      0.58      0.50       139\n",
            " kaden-channel       0.62      0.19      0.29       178\n",
            "livedoor-homme       0.15      0.25      0.19        83\n",
            "   movie-enter       0.54      0.81      0.64       182\n",
            "        peachy       0.44      0.08      0.14       173\n",
            "          smax       0.26      0.10      0.15       182\n",
            "  sports-watch       0.50      0.50      0.50       191\n",
            "    topic-news       0.23      0.11      0.15       170\n",
            "\n",
            "      accuracy                           0.35      1474\n",
            "     macro avg       0.37      0.34      0.31      1474\n",
            "  weighted avg       0.39      0.35      0.32      1474\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ABbPM-Eoiam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}